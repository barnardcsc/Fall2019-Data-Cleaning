{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning in Python: Working with MTA Turnstile Data\n",
    "### Why clean your data?\n",
    "- It makes everything easier\n",
    "- It makes your analyses and models more accurate\n",
    "- It's kind of required for most projects..\n",
    "- A lot of datasets are SUPER MESSY, like the one we're using today from the MTA\n",
    "\n",
    "### What dataset are we using? Why?\n",
    "\n",
    "This dataset is released every week, and consists of observations for every single turnstile in the MTA's subway network, for every 4 hours from the previous Sunday to Saturday. The dataset contains cumulative entries and exits from those turnstiles. For users who want to look at subway usage data, this is one of the only ways, and it is also incredibly difficult to comprehend at first. See: http://web.mta.info/developers/turnstile.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import date\n",
    "import matplotlib as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting a date range\n",
    "Note the format of the csv URLs: http://web.mta.info/developers/data/nyct/turnstile/turnstile_181124.txt\n",
    "\n",
    "The last part is a date, the thru date, 18-11-24, Nov 24, 2018.\n",
    "We want more than just one week's worth of data, so we'll create an array of dates in our range using a pandas function called date_range. \n",
    "\n",
    "Then, we'll create an array of URLs using the dates in the format the MTA uses, so that we can pull multiple CSVs at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "First, we'll clean up the column names. Then we'll work through some common issues in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating by station\n",
    "Right now, every observation represents one turnstile at one station at a particular date and time, with the cumulative entries and exits. However, we don't really care about individual turnstiles. They actually make it harder to read our data. For example, there will be more than 10 observations at the 116th street 1 station on 9/29/18 at 4 am alone. Instead, we'll group the data by station, line name, date, and time to find the sum of cumulative entries and exits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing entries at odd times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This particular section has a couple of problems. Not only is the entry/exit counter resetting, but if you look closely at the datetimes, you'll notice that some of the observations are not 4 hours apart. First, we'll create a variable for the difference in time between an observation and the following observation. Then, we'll need to remove an observation if it's time difference is not 4, AND if the one after is also not 4. This is because we wouldn't want to drop the 10/15 observation at 12 pm, but we would want to drop the 10/15 observations at 9:24 and 10:47."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating entries and exits, non-cumulative\n",
    "Cumulative entries and exits do very little for us. We would much rather know the number of entries and exits in each 4 hour period. Also, sometimes the cumulative count will reset, throwing calculations off. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locating and removing outliers\n",
    "For data of this nature, there will be a lot of variability, because some stations get a lot more traffic than others, and some times are much busier than others. First, we'll 'describe' our ent and ext variables, to better understand their distribution. We'll find that there are some entries less than zero, which is impossible, so we'll remove observations with entries or exits less than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
